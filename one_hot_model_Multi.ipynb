{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff6d38-4710-4e8d-be47-09a781821e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "\n",
    "# import python libraries  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from importlib import reload\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from models.one_hot_drugs_models import build_Phos_Prot_CNN \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scripts.data_wrangling import import_phos\n",
    "from scripts.feature_selection import fs_landmark, fs_atlas_landmark, true_phosphosite_filter\n",
    "from scripts.data_preparation import data_prep\n",
    "from scripts.data_selection import data_indexing\n",
    "from scripts.model_training import train_model_multi, prediction_metrics, scheduler, split_all_scores\n",
    "\n",
    "print('Imports: Done')\n",
    "tf.keras.utils.set_random_seed(524) # 524, 270, 345\n",
    "\n",
    "## Data Wrangling, feature selection and preparation\n",
    "\n",
    "# Import and wrangle phosphoproteomics, proteomics and GDSC1 drug data\n",
    "phos_df, prot_df, drug_df, drug_matrix, _all_cls, _all_drugs, common_ind = import_all()\n",
    "\n",
    "# create list of phosphosites filtered by feature selection method\n",
    "phosphosites = fs_atlas_landmark(phos_df,80)\n",
    "# remove false positive phosphosites\n",
    "filtered_phosphosites = true_phosphosite_filter(phosphosites)\n",
    "# reduce remaining features down by feature selection\n",
    "phos_df = phos_df.filter(filtered_phosphosites,axis=1)\n",
    "\n",
    "# create list of landmark gene proteins\n",
    "landmark_proteins = fs_landmark(prot_df)\n",
    "# reduce remaining features down by feature selection\n",
    "prot_df = prot_df.filter(landmark_proteins,axis=1)\n",
    "\n",
    "## Data Preparation & Selection\n",
    "x_drug, x_all_phos, y_series = data_prep(drug_df,phos_df,common_ind)\n",
    "x_drug, x_all_prot, y_series = data_prep(drug_df,prot_df,common_ind)\n",
    "# import stored training and testing pairs \n",
    "with open (f'train_test_pairs/_train_test_pairs_1.ob', 'rb') as fp:\n",
    "    train_test_list = pickle.load(fp)\n",
    "\n",
    "## Training model and testing\n",
    "\n",
    "all_scores = []\n",
    "trials = len(train_test_list) # number of train/test splits tested \n",
    "epochs = 60 # max training epochs (60)\n",
    "\n",
    "for i in range(trials):\n",
    "    print(f\"\\nTrial {i+1}\\n\")\n",
    "    \n",
    "    # select train and test pairs\n",
    "    train_pairs = train_test_list[i][0]\n",
    "    test_pairs  = train_test_list[i][1]\n",
    "    # index for each set of train-test pairs\n",
    "    xo_train_phos, xd_train, y_train, xo_test_phos, xd_test, y_test = data_indexing(train_pairs,test_pairs,x_all_phos,x_drug,y_series) \n",
    "    xo_train_prot, xd_train, y_train, xo_test_prot, xd_test, y_test = data_indexing(train_pairs,test_pairs,x_all_prot,x_drug,y_series)\n",
    "\n",
    "    m_func = build_Phos_Prot_CNN(x_all_phos,x_all_prot,x_drug) # set model and parameters\n",
    "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler) # set learning rate scheduler\n",
    "\n",
    "    scores = train_model_multi(m_func,lr_scheduler, \n",
    "                               x_train = [xo_train_phos, xo_train_prot, xd_train], \n",
    "                               x_test = [xo_test_phos, xo_test_prot, xd_test], \n",
    "                               y_train = y_train, y_test = y_test, \n",
    "                               epochs = epochs)\n",
    "            \n",
    "    all_scores.append(scores)\n",
    "    \n",
    "# split scores into individual lists\n",
    "r2_scores, mse_scores, pearson_scores = split_all_scores(all_scores)\n",
    "\n",
    "# find mean of all scores    \n",
    "print('\\nmean r2: ',np.mean(r2_scores))\n",
    "print('\\nr2 scores:')\n",
    "print(*r2_scores, sep = '\\n')\n",
    "\n",
    "# find mean of all scores    \n",
    "print('\\nmean mse: ',np.mean(mse_scores))\n",
    "print('\\nr2 scores:')\n",
    "print(*mse_scores, sep = '\\n')\n",
    "\n",
    "# find mean of all scores    \n",
    "print('\\nmean pearson: ',np.mean(pearson_scores))\n",
    "print('\\nr2 scores:')\n",
    "print(*pearson_scores, sep = '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
